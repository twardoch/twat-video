# this_file: pyproject.toml
# this_project: twat_video

# Build System Configuration
# -------------------------
# Specifies the build system and its requirements for packaging the project
# Specifies the build backend and its requirements for building the package
[build-system]
requires = [
    "hatchling>=1.27.0",     # Core build backend for Hatch
    "hatch-vcs>=0.4.0",      # Version Control System plugin for Hatch
]
build-backend = "hatchling.build"  # Use Hatchling as the build backend

# Wheel build configuration
# Specifies which packages to include in the wheel distribution
[tool.hatch.build.targets.wheel]
packages = ["src/twat_video"]

# Project Metadata Configuration
# ------------------------------
# Comprehensive project description, requirements, and compatibility information
[project]
name = "twat-video"
dynamic = ["version"]  # Version is determined dynamically from VCS
description = ""
readme = "README.md"
requires-python = ">=3.10"  # Minimum Python version required
license = "MIT"
keywords = []
classifiers = [
    "Development Status :: 4 - Beta",
    "Programming Language :: Python",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: Implementation :: CPython",
    "Programming Language :: Python :: Implementation :: PyPy",
]

# Runtime Dependencies
# -------------------
# External packages required for the project to function
dependencies = [
]


[[project.authors]]
name = "Adam Twardoch"
email = "adam+github@twardoch.com"


[project.urls]
Documentation = "https://github.com/twardoch/twat-video#readme"
Issues = "https://github.com/twardoch/twat-video/issues"
Source = "https://github.com/twardoch/twat-video"




[tool.hatch.version]
source = "vcs"
# raw-options are not needed for basic hatch-vcs usage with version-file
# and the previous option was for setuptools-scm

[tool.hatch.build.hooks.vcs]
version-file = "src/twat_video/__version__.py"



[tool.hatch.envs.default]
dependencies = [
    "pytest",
    "pytest-cov",
    "mypy>=1.0.0",
    "ruff>=0.1.0",
    "uv>=0.1.17", # Added uv
]


[tool.hatch.envs.default.scripts]
# Ensure uv is used for running tools if they are managed by hatch's environment
# Or explicitly use 'uv run' for tools that might not be directly on PATH from hatch env
test = "uv run pytest {args:tests}"
test-cov = "uv run pytest --cov-report=term-missing --cov-config=pyproject.toml --cov=src/twat_video --cov=tests {args:tests}"
type-check = "uv run mypy src/twat_video tests"
# For linting, ruff is typically installed into the environment by Hatch.
# If Hatch places binaries in a way that `uv run` is beneficial, use it. Otherwise, direct call is fine.
# Assuming direct call is fine after Hatch setup for these.
lint = ["uv run ruff check src/twat_video tests", "uv run ruff format --check src/twat_video tests"]
format = "uv run ruff format src/twat_video tests" # Added explicit format script
# Script to install/update tools using uv
tools-install = "uv pip install --upgrade pytest pytest-cov mypy ruff"


[[tool.hatch.envs.all.matrix]]
python = ["3.10", "3.11", "3.12"]


[tool.hatch.envs.lint]
detached = true
dependencies = [
    "mypy>=1.0.0",
    "ruff>=0.1.0",
    "uv>=0.1.17", # Added uv
]


[tool.hatch.envs.lint.scripts]
typing = "uv run mypy --install-types --non-interactive {args:src/twat_video tests}"
style = ["uv run ruff check {args:.}", "uv run ruff format --check {args:.}"] # Added --check
fmt = ["uv run ruff format {args:.}", "uv run ruff check --fix {args:.}"]
all = ["style", "typing"]
# Script to install/update linting tools using uv
tools-install-lint = "uv pip install --upgrade mypy ruff"


[tool.ruff]
target-version = "py310"
line-length = 88
lint.extend-select = [
    "A",
    "ARG",
    "B",
    "C",
    "DTZ",
    "E",
    "EM",
    "F",
    "FBT",
    "I",
    "ICN",
    "ISC",
    "N",
    "PLC",
    "PLE",
    "PLR",
    "PLW",
    "Q",
    "RUF",
    "S",
    "T",
    "TID",
    "UP",
    "W",
    "YTT",
]
lint.ignore = [
    "ARG001", # Unused function argument
    "E501",   # Line too long
    "I001",
]

[tool.ruff.lint.isort]
known-first-party = ["twat_video"]

[tool.ruff.lint.flake8-tidy-imports]
ban-relative-imports = "all"

[tool.ruff.lint.per-file-ignores]
"tests/**/*" = [
    "PLR2004",  # Allow magic values in tests for readability
    "S101",     # Allow assertions in tests
    "TID252"    # Allow relative imports in tests for convenience
]


[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true


[tool.coverage.run]
source_pkgs = ["twat_video", "tests"]
branch = true
parallel = true
omit = [
    "src/twat_video/__about__.py",
]


[tool.coverage.paths]
twat_video = ["src/twat_video", "*/twat-video/src/twat_video"]
tests = ["tests", "*/twat-video/tests"]


[tool.coverage.report]
exclude_lines = [
    "no cov",
    "if __name__ == .__main__.:",
    "if TYPE_CHECKING:",
]

[project.optional-dependencies]
test = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "pytest-xdist>=3.5.0",  # For parallel test execution
    "pytest-benchmark[histogram]>=4.0.0",  # For performance testing
]

dev = [
    "pre-commit>=3.6.0",
    "ruff>=0.1.0",
    "mypy>=1.0.0",
]

all = []

[tool.hatch.envs.test]
dependencies = [".[test]"]

[tool.hatch.envs.test.scripts]
# Use uv run for consistency, though python -m pytest is also fine as pytest is a dependency.
test = "uv run pytest -n auto {args:tests}"
test-cov = "uv run pytest -n auto --cov-report=term-missing --cov-config=pyproject.toml --cov=src/twat_video --cov=tests {args:tests}"
bench = "uv run pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only {args}"
bench-save = "uv run pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only --benchmark-json=benchmark/results.json {args}"

[tool.pytest.ini_options]
markers = ["benchmark: marks tests as benchmarks (select with '-m benchmark')"]
addopts = "-v -p no:briefcase"
testpaths = ["tests"]
python_files = ["test_*.py"]
filterwarnings = ["ignore::DeprecationWarning", "ignore::UserWarning"]
asyncio_mode = "auto"

[tool.pytest-benchmark]
min_rounds = 100
min_time = 0.1
histogram = true
storage = "file"
save-data = true
compare = [
    "min",    # Minimum time
    "max",    # Maximum time
    "mean",   # Mean time
    "stddev", # Standard deviation
    "median", # Median time
    "iqr",    # Inter-quartile range
    "ops",    # Operations per second
    "rounds", # Number of rounds
]
